# 神经网络：反向传播

我们可以用数学表示我们的神经网络模型：

$$
h(x)=h(\omega x + b)
$$

神经网络模型也是一种判别模型，即直接根据数据来构造模型进行预测和分类。这个学习的过程，实际上就是通过调整模型中的参数$\omega$和$b$，使得代价函数达到极小值。代价函数的求解依然是通过梯度下降法。

Anyway，求梯度是不可避免的。从变分的角度说，代价函数实际上是参数$\omega$和$b$的泛函，我们要求的是某个$\omega$和$b$让泛函达到极小。反向传播的作用，实际上就是让梯度的下降能够影响参数$\omega$和$b$的取值，即参数$\omega$和$b$的取值是根据代价函数的大小来的。

为了能够推导出反向传播的数学表达式，我们首先建立神经网络的具体数学模型：

$$
x^{l+1} = f[z^{l+1}] \\
z^{l+1} = \omega^{l} x^{l} + b^{l}
$$

公式中的$l$表示第$l$层，其他均用向量表示，不写下标。

我们要求的梯度：

$$
\nabla_{\omega^l}J=\dfrac{\partial J}{\partial z^{l+1}}\dfrac{\partial z^{l+1}}{\partial \omega^l}=\delta^{l+1}(x^l)^T \\
\nabla_{b^l}J=\dfrac{\partial J}{\partial z^{l+1}}\dfrac{\partial z^{l+1}}{\partial b^l}=\delta^{l+1} \\
\delta^l=\dfrac{\partial J}{\partial z^{l}}=\dfrac{\partial J}{\partial z^{l+1}}\dfrac{\partial z^{l+1}}{\partial x^l}\dfrac{\partial x^l}{\partial z^l}=(\omega^l)^T \delta^{l+1} f'(z^l)
$$

这就是整个反向传播算法中用到的数学公式。

具体的算法如下：

1. 首先进行前向传播，计算得到各个隐藏层的参数值和最终输出值，并计算代价函数；
2. 对输出层第$l$层计算代价函数，并计算出$\delta^l=\dfrac{\partial J}{\partial z^{l}}$；
3. 对隐藏层，利用公式$\delta^l=(\omega^l)^T \delta^{l+1} f'(z^l)$逐层向下计算；
4. 然后就可以求得梯度$\nabla_{\omega^l}J$和$\nabla_{b^l}J$;
5. 根据梯度值更新参数$\omega$和$b$的取值；