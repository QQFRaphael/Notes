> 隐马尔可夫模型是可以用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。隐马尔科夫模型在语音识别，自然语言处理等方面应用较多。

# 马尔可夫链

马尔可夫链是满足马尔可夫性质的随机过程：设$ \{ X(t), t \in T \}$是一个随机过程，如果该随机过程在$t_0$时刻所处的状态为已知的时候，$t_0$时刻以后的状态与它在$t_0$之前的状态无关，即$P(X_{n+1}=x|X_1=x_1,X_2=x_2,...,X_n=x_n)=P(X_{n+1}=x|X_n=x_n)$

平稳性：下一个状态的分布和之前保持一致，即$P(z_t|z_{t-1})=P(z_2|z_1),t=2,3,...,T$

# 隐马尔可夫模型

隐马尔可夫模型描述的是一个隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测，从而产生观测随机序列的过程。隐藏的马尔可夫链随机生成的状态的序列，称为状态序列；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列。序列的每个位置也可以看做是一个时刻。隐马尔可夫模型由初始概率分布、状态转移概率分布以及观测概率分布确定。

设$Q=\{q_1,q_2,...,q_N\}$为所有可能的状态的集合，$V=\{v_1,v_2,...,v_M\}$是所有可能的观测的集合，其中$N$为可能的状态数，$M$是可能的观测数。$I= \{ i_1, i_2,...,i_T\}$是长为$T$的状态序列，$O = \{ o_1,o_2,...,o_T\}$是对应的观测序列。

设状态转移概率矩阵$A=[a_{ij}]_{N\times N}$，其中，$a_{ij}=P(i_{t+1}=q_j|i_t=q_i),i=1,2,...,N; j=1,2,...,N$是在$t$时刻处于状态$q_i$的条件下在时刻$t+1$时刻转移到状态$q_j$的概率

设观测概率矩阵$B=[b_j(k)]_{N \times M}$，其中，$b_j(k) = P(o_t=v_k|i_t=q_j),k=1,2,...,M; j=1,2,...,N$是在时刻$t$处于状态$q_j$的条件下生成观测$v_k$的概率

设初始状态概率向量$\pi=(\pi_i)$，其中，$\pi_i=P(i_1=q_i), i=1,2,...,N$是初始时刻$t=1$处于状态$q_i$的概率

状态转移概率矩阵和初始状态概率向量确定了隐马尔可夫链，总而生成不可观测的状态序列。观测概率矩阵确定了如何生成观测，与状态序列共同确定了观测序列

隐马尔可夫模型可以表示为$\lambda = (A,B,\pi)$

隐马尔可夫模型做了两个假设，一个是齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻的状态只依赖于前一时刻的状态，而与其他时刻的状态及观测无关，也与时刻本身无关；另一个假设是观测独立性假设，假设任意时刻的观测是依赖于该时刻的马尔可夫链的状态，而与其他观测和状态无关。

隐马尔可夫模型有三个基本问题：

1. 概率计算问题，给定模型和观测序列，计算模型条件下观测序列出现的概率$P(O|\lambda)$
2. 学习问题，已知观测序列，估计模型参数，使得该模型下观测序列概率$P(O| \lambda)$最大，即用极大似然法估计参数
3. 预测问题，即给定观测序列，求最有可能的对应的状态序列

### 观测序列的生成

观测序列的生成过程如下：

1. 按照初始状态分布$\pi$产生状态$i_1$；
2. 令 $t=1$；
3. 按照状态$i_t$的观测概率分布$b_{i_t}(k)$生成观测值$o_t$；
4. 按照状态$i_t$的状态转移概率分布$\{ a_{i_t i_{t+1}}\}$产生状态$i_t$；
5. 令$t=t+1$，如果$t<T$，回到3，否则终止

### 概率计算算法

概率计算也可以直接计算，但是计算量很大。可以采用前向-后向算法

##### 前向算法

前向概率：给定马尔科夫模型，定义到时刻t的部分观测序列$o_1,o_2,...,o_t$且状态为$q_i$的概率为前向概率，记为$\alpha_t(i) = P(o_1,o_2,...,o_t,i_t=q_i|\lambda)$，本质是观测和状态的联合分布

前向算法如下：

1. 初值$\alpha_1(i)=\pi_i b_i(o_1), i=1,2,...,N$
2. 递推：对于$t=1,2,...,T-1$，计算$\alpha_{t+1}(i) = [\sum_{j=1}^N \alpha_t(j) a_{ji}]b_i(o_{t+1}), i=1,2,...,N$
3. 终止：$P(O|\lambda)=\sum_{i=1}^N \alpha_T(i)$

其实这个算法本身理解并不难，我们把每一项表示为概率：

1. 初值$\alpha_1(i)=\pi_i b_i(o_1)=P(i_1=q_i)P(o_1|i_1=q_i)=P(o_1, i_1 = q_i), i=1,2,...,N$，实际上就是初始时刻观测为$o_1$和状态为$q_i$的联合概率分布
2. $\alpha_t(j) a_{ji} = P(o_t,i_t=q_j)P(i_{t+1}=q_i|i_t = q_j)=P(o_t,i_{t+1}=q_i,i_t = q_j)$，这实际上就是t时刻观测是$o_t$，状态是$q_j$，然后下一个时刻状态是$q_i$的联合概率分布，将这个分布求和消去j，得到的实际上就是t时刻观测是$o_t$并且下一个时刻状态是$q_i$的联合概率分布$P(o_t,i_{t+1}=q_i)$，这一项与$b_i(o_{t+1})=P(o_{t+1}|i_{t+1}=q_i)$的乘积，实际上就是t+1时刻观测到$o_{t+1}$，同时处于状态$q_i$的概率，这就是t+1时刻的前向概率
3. 求和实际上就是对所有能够产生观测$o_{t+1}$的状态求和，最终得到t+1时刻状态为$o_{t+1}$的概率

##### 后向算法

后向概率：给定马尔科夫模型，定义在时刻t状态为$q_i$的条件下，后续的部分观测序列$o_{t+1},...,o_T$的概率为后向概率，记为$\beta_t(i)=P(o_{t+1},o_{t+2},...,o_T|i_t = q_i, \lambda)$

后向算法如下：

1. $\beta_T(i)=1, i=1,2,...,N$

2. 对$t=T-1, T-2, ..., 1$:
   $$
   \beta_t(i) = \sum_{j=1}^N a_{ij} b_j(o_{t+1})\beta_{t+1}(j), i=1,2,...,N
   $$

3. $P(O|\lambda) = \sum_{i=1}^N \pi_i b_i(o_1) \beta_1(i)$

第一步实际上是一种强制规定，认为最终时刻所有状态的后向概率为1。第二步，实际上就是先计算
$$
P(i_{t+1}=q_j|i_t = q_i) P(o_{t+1}|i_{t+1} = q_j) P(o_{t+2},o_{t+3},...,o_T|i_{t+1}=q_j)=P(i_{t+1}=q_j|i_t = q_i) P(o_{t+1},o_{t+2},o_{t+3},...,o_T|i_{t+1}=q_j) = P(o_{t+1},o_{t+2},o_{t+3},...,o_T|i_t = q_i)
$$
这样得到的就是前一时刻的后向概率。第三步，计算的是
$$
P(i_1=q_i)P(o_1|i_1=q_i)P(o_2,...,o_T|i_1=q_i)=P(o_1,o_2,...,o_T,i_1=q_i)
$$
实际上得到的就是所有可能产生这个观测序列的初始状态和观测序列的联合分布，然后对所有状态求和，就得到观测序列的概率分布

利用前向概率和后向概率可以将观测序列概率分布统一成：
$$
P(O|\lambda)=\sum_{i=1}^N \sum_{j=1}^N \alpha_t(i) a_{ij} b_j(o_{t+1}) \beta_{t+1}(j), t = 1,2,...,T-1
$$

##### 一些概率与期望值的计算

1. 给定模型和观测，在t时刻处于状态$q_i$的概率记为
   $$
   \gamma_t(i)=P(i_t=q_i|O,\lambda)=\dfrac{P(i_t=q_i,O,\lambda)}{P(O|\lambda)}=\dfrac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N \alpha_t(i)\beta_t(i)}
   $$

2. 给定模型和观测，在t时刻处于状态$q_i$并且下一时刻处于状态$q_j$的概率记为
   $$
   \xi_t(i,j)=\dfrac{P(i_t=q_i,i_{t+1}=q_j,O|\lambda)}{P(O|\lambda)}=\dfrac{P(i_t=q_i,i_{t+1}=q_j,O|\lambda)}{\sum_{i=1}^N\sum_{j=1}^N P(i_t=q_i,i_{t+1}=q_j,O|\lambda)}=\dfrac{\alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)}{\sum_{i=1}^N\sum_{j=1}^N \alpha_t(i)a_{ij}b_j(o_{t+1})\beta_{t+1}(j)}
   $$

3. 在观测$O$下状态$q_i$出现的期望：
   $$
   \sum_{t=1}^T \gamma_t(i)
   $$

4. 在观测$O$下由状态$q_i$转移的期望：
   $$
   \sum_{t=1}^{T-1} \gamma_t(i)
   $$

5. 在观测$O$下由状态$q_i$转移到状态$q_j$的期望值：
   $$
   \sum_{t=1}^{T-1} \xi_t(i,j)
   $$




### 学习算法

> 隐马尔可夫模型的学习，如果给出的训练数据是观测序列和状态序列，则是监督学习；如果只有观测序列，则是非监督学习。非监督学习可以用Baum-Welch算法，也就是EM算法

##### 监督学习方法

假设给定观测序列和对应的状态序列$\{ (O_1,I_1), (O_2,I_2), ..., (O_S,I_S)\}$，可以利用极大似然法估计参数。算法如下：

1. 转移概率$a_{ij}$的估计

   设样本中t时刻处于状态$q_i$，下一时刻转移到状态$q_j$的频数是$A_{ij}$，那么状态转移概率$a_{ij}$的估计是：
   $$
   \hat{a_{ij}}=\dfrac{A_{ij}}{\sum_{j=1}^N A_{ij}},i=1,2,...,N;j=1,2,...,N
   $$

2. 观测概率$b_j(k)$的估计

   设样本中状态为$q_j$且观测为$o_k$的频数是$B_{jk}$，那么状态为$q_j$观测为$o_k$的概率$b_j(k)$的估计是：
   $$
   \hat{b_j(k)}=\dfrac{B_{jk}}{\sum_{k=1}^M B_{jk}},j=1,2,...,N;k=1,2,...,M
   $$

3. 初始状态概率$\pi_i$的估计$\hat{\pi_i}$为$S$个样本中初始状态为$q_i$的频率

##### Baum-Welch算法

假设给定的训练数据只有观测序列$\{ O_1, O_2,...,O_S \}$，那么隐马尔可夫模型实际上就是一个含有隐变量的概率模型：$P(O|\lambda)=\sum_I P(O|I,\lambda)P(I|\lambda)$，算法如下：

1. 确定完全数据的对数似然函数

   所有观测数据写成$O=(o_1,o_2,...,o_T)$，所有隐数据写为$I=(i_1,i_2,...,i_T)$，完全数据是$(O,I)=(o_1,o_2,...,o_T,i_1,i_2,...,i_T)$，完全数据的对数似然函数是$log P(O,I|\lambda)$

2. EM算法的E步：求Q函数

   $\overline{\lambda}$是隐马尔可夫模型参数的当前估计值，$\lambda$是要极大化的隐马尔可夫模型参数
   $$
   Q(\lambda,\overline{\lambda})=\sum_I log P(O,I|\lambda)P(O,I|\overline{\lambda})=\sum_I log \pi_{i_t}P(O,I|\overline{\lambda})+\sum_I(\sum_{t=1}^{T-1}log a_{i_t i_{t+1}})P(O,I|\overline{\lambda})+\sum_I(\sum_{t=1}^T log b_{i_t}(o_t))P(O,I|\overline{\lambda})
   $$
   上式中所有求和都是对所有训练数据总长度T

   上式能够展开，是因为有关系：
   $$
   P(O,I|\lambda)=\pi_{i_1}b_{i_1}(o_1)a_{i_1 i_2}b_{i_2}(o_2)...a_{i_{T-1}i_T}b_{i_T}(o_T)
   $$

3. EM算法的M步：极大化Q函数从而得到模型

   a. 2中的第一项
   $$
   \sum_I log \pi_{i_0}P(O,I|\overline{\lambda})=\sum_{i=1}^N log \pi_{i_i}P(O,i_1=i|\overline{\lambda})
   $$
   由于$\pi_i$满足约束条件$\sum_{i=1}^N \pi_i=1$，然后可以通过拉格朗日乘数法求得参数$\pi_i$的表达式
   $$
   \pi_i = \dfrac{P(O,i_1=i|\overline{\lambda})}{P(O|\overline{\lambda})}=\gamma_1(i)
   $$
   b. 2中的第二项
   $$
   \sum_I(\sum_{t=1}^{T-1}log a_{i_t i_{t+1}})P(O,I|\overline{\lambda})=\sum_{i=1}^N \sum_{j=1}^N \sum_{t=1}^{T-1} log a_{ij} P(O,i_t=i,i_{t+1}=j|\overline{\lambda})
   $$
   约束条件$\sum_{j=1}^N a_{ij}=1$，利用拉格朗日乘数法得到：
   $$
   a_{ij}=\dfrac{\sum_{t=1}^{T-1}P(O,i_t=i,i_{t+1}=j|\overline{\lambda})}{\sum_{t=1}^{T-1}P(O,i_t=i|\overline{\lambda})}=\dfrac{\sum_{t=1}^{T-1}\xi_t(i,j)}{\sum_{t=1}^{T-1}\gamma_t(i)}
   $$
   c. 2中的第三项
   $$
   \sum_I(\sum_{t=1}^T log b_{i_t}(o_t))P(O,I|\overline{\lambda})=\sum_{j=1}^N \sum_{t=1}^T log b_j(o_t)P(O,i_t=j|\overline{\lambda})
   $$
   约束条件$\sum_{k=1}^M b_j(k)=1$，注意只有当$o_t=v_k$时$b_j(o_t)$对$b_j(k)$的偏导数才不为0，用$I(o_t=v_k)$表示，用拉格朗日乘数法得到：
   $$
   b_j(k)=\dfrac{\sum_{t=1}^T P(O,i_t=j|\overline{\lambda})I(o_t=v_k)}{\sum_{i=1}^T P(O,i_t=j|\overline{\lambda})}=\dfrac{\sum_{t=1,o_t=v_k}^T \gamma_t(j)}{\sum_{t=1}^T \gamma_t(j)}
   $$




综上，Baum-Welch算法的步骤如下：

1. 初始化，计算$a,b,\pi$的初始值
2. 递推，计算每步的$a,b,\pi$值
3. 得到模型参数

### 预测算法

##### 近似算法

近似算法的想法是，在每个时刻t选择在该时刻最有可能出现的状态，从而得到一个状态序列，并把这个状态序列作为预测结果

给定马尔科夫模型和观测序列，在时刻t处于状态$q_i$的概率$\gamma_t(i)$的概率是：
$$
\gamma_t(i)=\dfrac{\alpha_t(i)\beta_t(i)}{P(O|\lambda)}=\dfrac{\alpha_t(i)\beta_t(i)}{\sum_{j=1}^N \alpha_t(j) \beta_t(j)}
$$
在每个时刻t最有可能的状态$i_t^*$是
$$
i_t^*=argmax_{1\le i \le N}[\gamma_t(i)],t=1,2,...,T
$$
从而得到状态序列

预测算法虽然简单，但缺点是不能保证预测状态序列整体是最有可能的状态序列

##### 维特比算法

维特比算法实际上用动态规划求解概率最大路径，这一路径对应着一个状态序列

根据动态规划原理，最优路径具有这样的特性：如果最优路径在时刻t通过节点$i_t^*$，那么这一路径从节点$i_t^*$到终点$i_T^*$的部分路径，对于从$i_t^*$到$i_T^*$的所有可能的部分路径来说，必须是最优的。所以，只需要从t=1开始，递推计算时刻t状态为$q_i$的各条部分路径的最大概率，时刻t=T的最大概率即为最优路径的概率，也就得到了路径的终节点。然后，再从后往前逐步求得每个节点，得到最优路径。

定义在时刻t状态为$i$的所有单个路径$(i_1,i_2,...,i_t)$中概率最大值为：
$$
\delta_t(i) = max_{i_1...i_{t-1}} P(i_t=i,...,i_1,o_t,...,o_1|\lambda), i=1,2,...,N
$$
然后可以得到递推公式：
$$
\delta_{t+1}(i)=max_{i_1,...i_t}P(i_{t+1}=i,i_t,...,i_1,o_{t+1},...,o_1|\lambda)=max_{1 \le j \le N}[\delta_t(j)a_{ji}]b_i(o_{t+1}),i=1,2,...,N;t=1,2,...,T-1
$$
定义在时刻t状态为$i$的所有单个路径$(i_1,...,i_{t-1},i)$中概率最大的路径的第$t-1$个节点为：
$$
\Psi_t(i)=argmax_{1 \le j \le N}[\delta_{t-1}(j)a_{ji}],i=1,2,...,N
$$
算法如下：

1. 初始化：
   $$
   \delta_1(i)=\pi_i b_i(o_1), \Psi_1(i) = 0
   $$

2. 递推，对于$t=2,3,...,T$：
   $$
   \delta_t(i)=max_{1 \le j \le N}[\delta_{t-1}(j)a_{ji}]b_i(o_t) \\
   \Psi_t(i)=argmax_{1 \le j \le N}[\delta_{t-1}(j)a_{ji}]
   $$

3. 终止：
   $$
   P^*=max_{1 \le i \le N}\delta_T(i) \\
   i_T^*=argmax_{1 \le i \le N}[\delta_T(i)]
   $$

4. 最优路径回溯，对于$t=T-1,...,1$：
   $$
   t_t^* = \Psi_{t+1}(i_{t+1}^*)
   $$
   从而得到最优路径$I^*=(i_1^*,...,i_T^*)$

