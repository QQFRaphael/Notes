# 最大熵模型

学习概率模型时，在所有可能的模型中，熵最大的模型是最好的模型。最大熵原理也可以表述为在满足约束的集合中选取熵最大的模型。

# 最大熵模型的定义

假设分类模型时一个条件概率分布$P(Y|X)$，$X$表示输入，$Y$表示输出。

首先考虑模型应该满足的条件。给定训练数据集，可以确定联合分布$P(X,Y)$的经验分布和边缘分布$P(X)$的经验分布，分别表示为：

$$
\tilde{P}(X=x,Y=y)=\dfrac{v(X=x,Y=y)}{N} \\
\tilde{P}(X=x)=\dfrac{v(X=x)}{N}
$$

其中，$v(X=x,Y=y)$表示训练数据中样本$(x,y)$出现的频数，$v(X=x)$表示训练数据中输入$x$出现的频数，$N$表示样本容量。

用特征函数$f(x,y)$描述$x$和$y$之间的某个事实，定义为：

$$
f(x,y)=\begin{cases}
1& x和y满足某一事实 \\
-1& 否则
\end{cases}
$$

特征函数关于经验分布的期望值：

$$
E_{\tilde{P}}(f)=\sum_{x,y}\tilde P(x,y)f(x,y)
$$

特征函数关于模型$P(Y|X)$和经验分布的期望值：

$$
E_P(f)=\sum_{x,y}\tilde P(x)P(y|x)f(x,y)
$$

如果模型能够获取训练数据中的信息，那么就可以假设这两个期望值相等：

$$
E_P(f)=E_{\tilde P}(f)
$$

或者

$$
\sum_{x,y}\tilde P(x)P(y|x)f(x,y)=\sum_{x,y}\tilde P(x,y)f(x,y)
$$

假设满足所有约束条件的模型集合为：

$$
C=\{P \in \mathcal{P}|E_P(f_i)=E_{\tilde P}(f_i),i=1,2,...,n\}
$$

定义在条件概率分布$P(Y|X)$上的条件熵为：

$$
H(P)=-\sum_{x,y}\tilde P(x)
P(y|x)log P(y|x)
$$

则模型集合$C$中条件熵最大的模型就是最大熵模型。

# 最大熵模型的学习

最大熵模型学习可以形式化为约束最优化问题。

$$
{max}_{P\in C} H(P)=-\sum_{x,y}\tilde P(x)
P(y|x)log P(y|x) \\
s.t. E_P(f_i)=E_{\tilde P}(f_i), i=1,2,...,n \\
\sum_y P(y|x)=1
$$

按照最优化问题的习惯，将求最大值问题可以改写为等价的求最小值问题：

$$
{min}_{P\in C} -H(P)=\sum_{x,y}\tilde P(x)
P(y|x)log P(y|x) \\
s.t. E_P(f_i)=E_{\tilde P}(f_i), i=1,2,...,n \\
\sum_y P(y|x)=1
$$

引入拉格朗日乘子$\omega_0,\omega_1,...,\omega_n$，定义拉格朗日函数$L(P,\omega)$：

$$
L(P,\omega)=-H(P)+\omega_0(1-\sum_y P(y|x))+\sum_{i=1}^n \omega_i (E_P(f_i)-E_{\tilde P}(f_i)) \\
= \sum_{x,y} \tilde P(x)P(y|x)log P(y|x)+\omega_0(1-\sum_y P(y|x))+\sum_{i=1}^n \omega_i (\sum_{x,y}\tilde P(x,y)f_i(x,y)-\sum_{x,y}\tilde P(x)P(y|x)f_i(x,y))
$$

首先观察拉格朗日函数，因为约束条件满足时，拉格朗日函数应该是关于$\omega$最大的，这样就可以写出最优化的原始问题：

$$
{min}_{P \in C} {max}_{\omega} L(P,\omega)
$$

对偶问题：

$$
{max}_{\omega} {min}_{P \in C} L(P,\omega)
$$

拉格朗日函数是$P$的凸函数，原始问题和对偶问题的解是等价的。

先解出对偶问题的内部的极小化问题${min}_{P \in C}L(P,\omega)$:

$$
\Psi (\omega)={min}_{P \in C}L(P,\omega)=L(P_\omega,\omega)
$$

$\Psi (\omega)$称为对偶函数，将解记为：

$$
P_\omega=arg{min}_{P \in C}L(P,\omega)=P_\omega(y|x)
$$

具体地，对$L(P,\omega)$对$P(y|x)$的偏导数：

$$
\dfrac{\partial L(P,\omega)}{\partial P(y|x)}=\sum_{x,y} \tilde P(x)(logP(y|x)+1)-\sum_y(\tilde P(x)\sum_{i=1}^n \omega_i f_i(x,y))=\sum_{x,y}(logP(y|x)+1-\omega_0-\sum_{i=1}^n \omega_i f_i(x,y))
$$

令偏导数为0，在$\tilde P(x)>0$的情况下，解得：

$$
P(y|x)=exp(\sum_{i=1}^n \omega_i f_i(x,y)+\omega_0-1)=\dfrac{exp(\sum_{i=1}^n \omega_i f_i(x,y))}{exp(1-\omega_0)}
$$

由于$\sum_yP(y|x)=1$，得：

$$
P_\omega(y|x)=\dfrac{1}{Z_\omega(x)}exp(\sum_{i=1}^n \omega_i f_i(x,y))
$$

其中，

$$
Z_\omega(x)=\sum_y exp(\sum_{i=1}^n \omega_i f_i(x,y))
$$

$Z_\omega(x)$称为规范化因子，而$P_\omega(y|x)$就是最大熵模型。

之后求解对偶问题外部的极大化问题：

$$
{max}_\omega \Psi(\omega)
$$

将其解记为$\omega^*$:

$$
\omega^*=arg{max}_\omega \Psi(\omega)
$$

最大熵模型的学习实际就是对偶函数$\Psi(\omega)$的极大化。

# 极大似然估计

已知训练数据的经验概率分布$\tilde P(X,Y)$，条件概率分布$P(Y|X)$的对数似然函数为：

$$
L_{\tilde P}(P_\omega)=log \prod_{x,y}P(y|x)^{\tilde P(x,y)}=\sum_{x,y}\tilde P(x,y)logP(y|x)
$$

当条件概率分布$P(y|x)$是最大熵模型时，对数似然函数为：

$$
L_{\tilde P}(P_\omega)=\sum_{x,y}\tilde P(x,y)logP(y|x) \\
= \sum_{x,y}\tilde P(x,y)\sum_{i=1}^n \omega_i f_i(x,y)-\sum_{x,y}\tilde P(x,y)log Z_\omega(x) \\
= \sum_{x,y}\tilde P(x,y)\sum_{i=1}^n \omega_i f_i(x,y)-\sum_{x}\tilde P(x)log Z_\omega(x) 
$$

再看对偶函数$\Psi(\omega)$：

$$
\Psi(\omega)=\sum_{x,y}\tilde P(x)P_\omega(y|x)logP_\omega(y|x)+\sum_{i=1}^n\omega_i(\sum_{x,y}\tilde P(x,y)f_i(x,y)-\sum_{x,y}\tilde P(x)P_\omega(y|x)f_i(x,y)) \\
=\sum_{x,y}\tilde P(x,y)\sum_{i=1}^n \omega_i f_i(x,y)+\sum_{x,y}\tilde P(x)P_\omega (y|x)(logP_\omega(y|x)-\sum_{i=1}^n\omega_i f_i(x,y)) \\
= \sum_{x,y}\tilde P(x,y)\sum_{i=1}^n \omega_i f_i(x,y)-\sum_{x,y}\tilde P(x)P_\omega(y|x)log Z_\omega(x) \\
=\sum_{x,y}\tilde P(x,y)\sum_{i=1}^n \omega_i f_i(x,y)-\sum_x \tilde P(x)log Z_\omega(x)
$$

最后一步用到$\sum_y P(y|x)=1$

然后我们就可以得到$\Psi(\omega)=L_{\tilde P}(P_\omega)$

对偶函数等价于对数似然函数。

最大熵模型的更一般的形式如下：

$$
P_\omega(y|x)=\dfrac{1}{Z_\omega(x)}exp(\sum_{i=1}^n \omega_i f_i(x,y)) \\
Z_\omega(x)=\sum_y exp(\sum_{i=1}^n \omega_i f_i(x,y))
$$

最大熵模型与逻辑斯蒂回归模型有类似的形式，它们又被称为对数线性模型。